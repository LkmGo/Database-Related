{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practicum, we are using MySQL and python to load a practical data file from the IMDB website and manipulate the data to designed tables. Also we built infrastructure for an application. With the built database, we created triggers, secure views, indexes, transactions, and complex queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#install the mysql connector: pip install mysql-connector-python\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from mysql.connector import errorcode\n",
    "import tarfile\n",
    "import pandas as pd\n",
    "import datatable as dt\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "\n",
    "import os\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to define SQLconnection\n",
    "def create_connection(host_name, user_name, user_password):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=host_name,\n",
    "            user=user_name,\n",
    "            passwd=user_password\n",
    "        )\n",
    "        print(\"Connection to MySQL DB successful\")\n",
    "    except Error as e:\n",
    "        print(f\"The error '{e}' occurred\")\n",
    "\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to parse the column with multipe values and convert them into rows\n",
    "def flatten_columns(df, col_toflat, index_coln, new_col_name, new_id_name):\n",
    "    \"\"\"https://medium.com/@sureshssarda/pandas-splitting-exploding-a-column-into-multiple-rows-b1b1d59ea12e\n",
    "    works for the case when columns is value1, value2,... \"\"\" \n",
    "    df = df.loc[df[col_toflat] != \"\\\\N\"].dropna(subset=[col_toflat])\n",
    "    flattened_df = pd.DataFrame(df[col_toflat].str.split(',').values.tolist(), index = df[index_coln]).stack()\n",
    "    flattened_df = flattened_df.reset_index()[[0, index_coln]] \n",
    "    flattened_df.columns = [new_col_name, new_id_name] # renaming\n",
    "    return flattened_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.A Create a ERD model in Crow's Foot\n",
    "create a data model in the form of an ERD in Crow's Foot notation using a tool of your choice (e.g., LucidChart, TOAD, MySQL Workbench, etc.) and embed an image of the model in your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ERD with original file tables](pics\\2A_ER.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the information provided from https://www.imdb.com/interfaces/, we generate a ER diagram for origianl data. In this diagram, there are some many-to-many relations and multi-valued attributes which will be normalized in 2.B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.B Create a ERD model with normalized tables\n",
    "Add junction/association tables to normalize many-to-many relationships, normalize multi-valued attributes, and create lookup tables for categorical attribute values. Embed an updated image of the model in your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ERD with normalized tables](pics\\2B_ER.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For table TitleCrew, we split it into two table TitleCrewWriter, TitleCrewDirector and deal with multi-values by process the data. Similarily, we deal with multi-values in TitlePrincipals Characters Columns, KnownForTitles in NameBasics, attributes and types in TitleBasics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.C Add two calculated columns\n",
    "add two new attributes (columns) to the appropriate tables: one for the age of a person and one for the number of movies a person has appeared in. Embed an updated image of the model in your notebook. Leave those columns empty for now. They will be filled in later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ERD with added columns](pics\\2C_ER.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two columns: age and number of movieds are added in NameBasics table as two calculated columns\n",
    "Those two columns are empty when we importing the data, and will be updated in the Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.D Ensure that the relational model is in at least BCNF\n",
    "ensure that the relational model is in at least BCNF, except for the columns added in step 2C.  In your notebook, answer: Why would someone choose to denormalize data as done in 2C?  (\"Because the assignment told us to\" is not a deep enough answer.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof of BCNF:\n",
    "<br>\n",
    "All columns in tables are only have one value inside\n",
    "<br>\n",
    "1. TitleBasics : tb_tconst is the unique identifier of the title. Other non-primary attributes also are not depends on each other.\n",
    "<br>\n",
    "2. TitleAKA: idTitleAKA is the id created as PK. Only PK is dependents on other attribtues\n",
    "<br>\n",
    "3. NameBasics: nb_nconst is the unique identifier of the name/person.Only PK is dependents on other attribtues\n",
    "<br>\n",
    "4. TitleCrewWriter: idTitleCrewcol is the id created as PK. Only PK is dependents on other attribtues\n",
    "<br>\n",
    "5. TitleCrewDirector: idTitleCrewDirector is the id created as PK. Only PK is dependents on other attribtues\n",
    "<br>\n",
    "6. TitleEpisode: idTitleEpisode is the id created as PK. idTitleEpisode-> (te_tconst, seasonNumber, episodeNumber)\n",
    "<br>\n",
    "7. TitlePrincipals: idTitlePrincipals is the id created as PK. idTitleEpisode-> (tp_tconst, tp_ordering, tp_nconst)\n",
    "<br>\n",
    "8. TitleRating: tr_tconst is the unique identifier of the title. It should be subset of the tb_tconst\n",
    "9. TitleAkaAttribute: idTitleAkaAttributes is the id created as PK. Only PK is dependents on other attribtues\n",
    "<br>\n",
    "10. KnownForTitles： idNameTitle is the id created as PK. Only PK is dependents on other attribtues\n",
    "<br>\n",
    "11. TitleAkaType：idTitleAkaType is the id created as PK. Only PK is dependents on other attribtues\n",
    "<br>\n",
    "12. PrincipalsCharacters：idPrincipalsCharacters is the id created as PK. Only PK is dependents on other attribtues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we add two new attributes as 2C is to make the information more convient for usages. Instead of birth year, age is more straightforward. Also the number of movies one perspn has appeared in is the another key information when we try to know the basic information of a person. Both information will be often queried by users. Adding these attributes will increase the efficiency of the query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "Create and then run CREATE TABLE statements to build the schema. These statements must run from within your notebook and not from a separate script. Ensure proper referential integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Read Stored Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can directly use the processed database for task 5-12 instead of running code in task 3 and 4. All formatted or processed data are store in sharefolder https://northeastern-my.sharepoint.com/:f:/g/personal/peng_x_northeastern_edu/ElLaPMZ1PhtPuxq1pI0CzmgBA0YA_KWxn4n7rt28Ri9d3Q?e=C6vnxT\n",
    "\n",
    "The stored database can be created by running sql namded as FinalPrac2DB.sql in sharefolder https://northeastern-my.sharepoint.com/:u:/g/personal/peng_x_northeastern_edu/EYJGTV6PCT1Ch2ijTjTl3O0BbWtfgzdgLWVS31cDV28UdQ?e=VpEr1h \n",
    "\n",
    "Importing stored Database with MySQL workbench: \n",
    "1. open one of your local MYSQL Connections \n",
    "2. run sql script\n",
    "3. set default schema name: practicum 2, default character set: utf8\n",
    "\n",
    "The importing process will last for few hours. Please use fill out your connection info in the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "engine =  mysql.connector.connect(user='root', password='',\n",
    "                              host='127.0.0.1',\n",
    "                              database='practicum2')\n",
    "db_cursor = engine.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating Database and Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make connection\n",
    "connection = create_connection(\"localhost\", \"root\", \"*********\")\n",
    "# creating database_cursor to perform SQL operation\n",
    "db_cursor = connection.cursor()\n",
    "# executing cursor with execute method and pass SQL query\n",
    "db_cursor.execute(\"CREATE DATABASE practicum2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the code for creating tables\n",
    "TABLES = {}\n",
    "\n",
    "TABLES['TitleBasics'] = (\n",
    "\" CREATE TABLE `TitleBasics` (\"\n",
    "  \"`tb_tconst` VARCHAR(500) NOT NULL,\"\n",
    "  \"`titleType` VARCHAR(500) NULL,\"\n",
    "  \"`primaryTitle` VARCHAR(500) NULL,\"\n",
    "  \"`originalTitle` VARCHAR(500) NULL,\"\n",
    "  \"`isAdult` TINYINT NULL,\"\n",
    "  \"`startYear` CHAR(4) NULL,\"\n",
    "  \"`endYear` CHAR(4) NULL,\"\n",
    "  \"`runtimeMinutes` INT NULL,\"\n",
    "  \"`genres1` VARCHAR(500) NULL,\"\n",
    "  \"`genres2` VARCHAR(500) NULL,\"\n",
    "  \"`genres3` VARCHAR(500) NULL,\"\n",
    "  \" PRIMARY KEY (`tb_tconst`)\"\n",
    "  \" )ENGINE = InnoDB\")\n",
    "\n",
    "TABLES['TitleAKA'] = (\n",
    "  \" CREATE TABLE `TitleAKA` (\"\n",
    "  \"`idTitleAKA` INT NOT NULL,\"\n",
    "  \"`titleID` VARCHAR(500) NULL,\"\n",
    "  \"`ordering` INT NULL,\"\n",
    "  \"`title` VARCHAR(1000) NULL,\"\n",
    "  \"`region` VARCHAR(500) NULL,\"\n",
    "  \"`IsOriginalTitle` VARCHAR(5) NULL,\"\n",
    "  \"`language` VARCHAR(20) NULL,\"    \n",
    "  \" PRIMARY KEY (`idTitleAKA`),\"\n",
    "  \" INDEX `tb_tconst_idx` (`titleID` ASC),\"\n",
    "  \" CONSTRAINT `taka_tb_tconst`\"\n",
    "  \"   FOREIGN KEY (`titleID`) REFERENCES  `TitleBasics` (`tb_tconst`)\"\n",
    "  \"   ON DELETE NO ACTION\"\n",
    "  \"   ON UPDATE NO ACTION\"\n",
    "  \" )ENGINE = InnoDB\")\n",
    "\n",
    "TABLES['NameBasics'] = (\n",
    "  \" CREATE TABLE `NameBasics` (\"\n",
    "  \"`nb_nconst` VARCHAR(500) NOT NULL,\"\n",
    "  \"`primaryName` VARCHAR(500) NULL,\"\n",
    "  \"`birthYear` CHAR(4) NULL,\"\n",
    "  \"`deathYear` CHAR(4) NULL,\"\n",
    "  \"`primaryProfession1` VARCHAR(500) NULL,\"\n",
    "  \"`primaryProfession2` VARCHAR(500) NULL,\"\n",
    "  \"`primaryProfession3` VARCHAR(500) NULL,\"\n",
    "  \"`age` INT NULL,\"\n",
    "  \"`numberOfMovies` INT NULL,\"\n",
    "  \" PRIMARY KEY (`nb_nconst`)\"\n",
    "  \" )ENGINE = InnoDB\")\n",
    "\n",
    "TABLES['TitleCrewWriter'] = (\n",
    "  \" CREATE TABLE `TitleCrewWriter` (\"\n",
    "  \"`idTitleCrewcol` INT NOT NULL,\"\n",
    "  \"`tcw_tconst` VARCHAR(500) NOT NULL,\"\n",
    "  \"`writers` VARCHAR(500) NULL,\"\n",
    "  \" PRIMARY KEY (`idTitleCrewcol`),\"\n",
    "  \" INDEX `nb_nconst_idx` (`writers` ASC),\"\n",
    "  \" CONSTRAINT `tcw_tb_tconst`\"\n",
    "  \"  FOREIGN KEY (`tcw_tconst`)\"\n",
    "  \"  REFERENCES `TitleBasics` (`tb_tconst`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION,\"\n",
    "  \" CONSTRAINT `tcw_nb_nconst`\"\n",
    "  \"  FOREIGN KEY (`writers`)\"\n",
    "  \"  REFERENCES `NameBasics` (`nb_nconst`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION\"\n",
    "  \" )ENGINE = InnoDB\")\n",
    "\n",
    "TABLES['TitleCrewDirector'] = (\n",
    "  \"  CREATE TABLE `TitleCrewDirector` (\"\n",
    "  \"`idTitleCrewDirector` INT NOT NULL,\"\n",
    "  \"`tcd_tconst` VARCHAR(500) NOT NULL,\"\n",
    "  \"`director` VARCHAR(500) NOT NULL,\"\n",
    "  \" PRIMARY KEY (`idTitleCrewDirector`),\"\n",
    "  \" INDEX `tb_tconst_idx` (`tcd_tconst` ASC),\"\n",
    "  \" INDEX `nb_nconst_idx` (`director` ASC),\"\n",
    "  \" CONSTRAINT `tcd_tb_tconst`\"\n",
    "  \"   FOREIGN KEY (`tcd_tconst`)\"\n",
    "  \"   REFERENCES `TitleBasics` (`tb_tconst`)\"\n",
    "  \"   ON DELETE NO ACTION \"\n",
    "  \"   ON UPDATE NO ACTION,\"\n",
    "  \" CONSTRAINT `tcd_nb_nconst`\"\n",
    "  \"   FOREIGN KEY (`director`)\"\n",
    "  \"   REFERENCES  `NameBasics` (`nb_nconst`)\"\n",
    "  \"   ON DELETE NO ACTION\"\n",
    "  \"   ON UPDATE NO ACTION\"\n",
    "  \" )ENGINE = InnoDB\")\n",
    "    \n",
    "    \n",
    "TABLES['TitleEpisode'] = (\n",
    "  \"  CREATE TABLE `TitleEpisode` (\"\n",
    "  \"`idTitleEpisode` INT NOT NULL,\"\n",
    "  \"`te_tconst` VARCHAR(500) NULL,\"\n",
    "  \"`parentTconst` VARCHAR(500) NULL,\"\n",
    "  \"`seasonNumber` INT NULL,\"\n",
    "  \"`episodeNumber` INT NULL,\"\n",
    "  \"PRIMARY KEY (`idTitleEpisode`),\"\n",
    "  \"INDEX `tb_tconst_idx` (`te_tconst` ASC),\"\n",
    "  \"INDEX `tb_tconst_idx1` (`parentTconst` ASC),\"\n",
    "  \"CONSTRAINT `te_tb_tconst`\"\n",
    "  \"  FOREIGN KEY (`te_tconst`)\"\n",
    "  \"  REFERENCES  `TitleBasics` (`tb_tconst`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION,\"\n",
    "  \"CONSTRAINT `te2_tb_tconst`\"\n",
    "  \"  FOREIGN KEY (`parentTconst`)\"\n",
    "  \"  REFERENCES  `TitleBasics` (`tb_tconst`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION\"\n",
    "  \")ENGINE = InnoDB\")\n",
    "\n",
    "TABLES['TitlePrincipals'] = (\n",
    "  \"CREATE TABLE `TitlePrincipals` (\"\n",
    "  \"`idTitlePrincipals` INT NOT NULL,\"\n",
    "  \"`tp_tconst` VARCHAR(500) NOT NULL,\"\n",
    "  \"`tp_ordering` VARCHAR(500) NULL,\"\n",
    "  \"`tp_nconst` VARCHAR(500) NOT NULL,\"\n",
    "  \"`category` VARCHAR(500) NULL,\"\n",
    "  \"`job` VARCHAR(500) NULL,\"\n",
    "  \"PRIMARY KEY (`idTitlePrincipals`),\"\n",
    "  \"INDEX `tb_tconst_idx` (`tp_tconst` ASC),\"\n",
    "  \"INDEX `nb_nconst_idx` (`tp_nconst` ASC),\"\n",
    "  \"CONSTRAINT `tb_tconst`\"\n",
    "  \"  FOREIGN KEY (`tp_tconst`)\"\n",
    "  \"  REFERENCES  `TitleBasics` (`tb_tconst`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION,\"\n",
    "  \"CONSTRAINT `nb_nconst`\"\n",
    "  \"  FOREIGN KEY (`tp_nconst`)\"\n",
    "  \"  REFERENCES  `NameBasics` (`nb_nconst`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION\"\n",
    "  \")ENGINE = InnoDB\")\n",
    "    \n",
    "TABLES['TitleRating'] = (\n",
    "  \"CREATE TABLE `TitleRating` (\"\n",
    "  \"`tr_tconst` VARCHAR(500) NOT NULL,\"\n",
    "  \"`averageRating` FLOAT NULL,\"\n",
    "  \"`numVotes` INT NULL,\"\n",
    "  \"PRIMARY KEY (`tr_tconst`),\"\n",
    "  \"CONSTRAINT `tr_tb_tconst`\"\n",
    "  \"  FOREIGN KEY (`tr_tconst`)\"\n",
    "  \"  REFERENCES  `TitleBasics` (`tb_tconst`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION\"\n",
    "  \")ENGINE = InnoDB\")\n",
    "    \n",
    "    \n",
    "TABLES['TitleAkaAttribute'] = (\n",
    "  \"CREATE TABLE `TitleAkaAttribute` (\"\n",
    "  \"`idTitleAkaAttributes` INT NOT NULL,\"\n",
    "  \"`taa_idAKA` INT NOT NULL,\"\n",
    "  \"`taa_attribute` VARCHAR(100) NULL,\"\n",
    "  \"PRIMARY KEY (`idTitleAkaAttributes`),\"\n",
    "  \"INDEX `idTitleAKA_idx` (`taa_idAKA` ASC),\"\n",
    "  \"CONSTRAINT `idTitleAKA`\"\n",
    "  \"  FOREIGN KEY (`taa_idAKA`)\"\n",
    "  \"  REFERENCES `TitleAKA` (`idTitleAKA`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION\"\n",
    "  \")ENGINE = InnoDB\")\n",
    "    \n",
    "    \n",
    "TABLES['KnownForTitles'] = (\n",
    "  \"CREATE TABLE `KnownForTitles` (\"\n",
    "  \"`idNameTitle` INT NOT NULL,\"\n",
    "  \"`kt_nconst` VARCHAR(500) NULL,\"\n",
    "  \"`kt_tconst` VARCHAR(500) NULL,\"\n",
    "  \"PRIMARY KEY (`idNameTitle`),\"\n",
    "  \"INDEX `nb_nconst_idx` (`kt_nconst` ASC),\"\n",
    "  \"INDEX `tb_tconst_idx` (`kt_tconst` ASC),\"\n",
    "  \"CONSTRAINT `knt_tb_tconst`\"\n",
    "  \"  FOREIGN KEY (`kt_tconst`)\"\n",
    "  \"  REFERENCES  `TitleBasics` (`tb_tconst`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION,\"\n",
    "  \"CONSTRAINT `knt_nb_nconst`\"\n",
    "  \"  FOREIGN KEY (`kt_nconst`)\"\n",
    "  \"  REFERENCES  `NameBasics` (`nb_nconst`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION\"\n",
    "  \")ENGINE = InnoDB\")\n",
    "    \n",
    "\n",
    "TABLES['TitleAkaType'] = (\n",
    "  \"CREATE TABLE `TitleAkaType` (\"\n",
    "  \"`idTitleAkaType` INT NOT NULL,\"\n",
    "  \"`tat_idAKA` INT NULL,\"\n",
    "  \"`type` ENUM('alternative', 'dvd', 'festival', 'tv', 'video', 'working', 'original', 'imdbDisplay') NULL,\"\n",
    "  \"PRIMARY KEY (`idTitleAkaType`),\"\n",
    "  \"INDEX `idTitleAKA_idx` (`tat_idAKA` ASC),\"\n",
    "  \"CONSTRAINT `taa_idTitleAKA`\"\n",
    "  \"  FOREIGN KEY (`tat_idAKA`)\"\n",
    "  \"  REFERENCES `TitleAKA` (`idTitleAKA`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION\"\n",
    "  \")ENGINE = InnoDB\")\n",
    "    \n",
    "    \n",
    "TABLES['PrincipalsCharacters'] = (\n",
    "  \"CREATE TABLE `PrincipalsCharacters` (\"\n",
    "  \"`idPrincipalsCharacters` INT NOT NULL,\"\n",
    "  \"`pc_idTitlePrincipals` INT NULL,\"\n",
    "  \"`character` VARCHAR(500) NULL,\"\n",
    "  \"PRIMARY KEY (`idPrincipalsCharacters`),\"\n",
    "  \"INDEX `idTitlePrincipals_idx` (`pc_idTitlePrincipals` ASC),\"\n",
    "  \"CONSTRAINT `idTitlePrincipals`\"\n",
    "  \"  FOREIGN KEY (`pc_idTitlePrincipals`)\"\n",
    "  \"  REFERENCES  `TitlePrincipals` (`idTitlePrincipals`)\"\n",
    "  \"  ON DELETE NO ACTION\"\n",
    "  \"  ON UPDATE NO ACTION\"\n",
    "  \")ENGINE = InnoDB\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in TABLES:\n",
    "    table_description = TABLES[table_name]\n",
    "    try:\n",
    "        print(\"Creating table {}: \".format(table_name), end='')\n",
    "        db_cursor.execute(table_description)\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "            print(\"already exists.\")\n",
    "        else:\n",
    "            print(err.msg)\n",
    "    else:\n",
    "        print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sqlalchemy engine\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@localhost/{db}\"\n",
    "                       .format(user=\"root\",\n",
    "                               pw=\"*********\",\n",
    "                               db=\"practicum2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 Load the data\n",
    "Load the data from the downloaded data files into the tables. Properly parse the foreign keys and attributes and ensure that the data is in the right tables in the right form and that referential integrity is ensured. This will require parsing code in your chosen programming language. You should create a subset of each dataset for testing (as the data sets are very large and take significant time to load). What is the effect of the referential integrity checking while you load? Can you do something about that? Describe and implement any improvement strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Read downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path = r'/prac2 data' # select your data path\n",
    "save_path = r'/formatted' # select your data path for processed data\n",
    "name_basics_file = 'name.basics.tsv.gz'\n",
    "title_aks_file = 'title.akas.tsv.gz'\n",
    "title_basics_file = 'title.basics.tsv.gz'\n",
    "title_crew_file = 'title.crew.tsv.gz'\n",
    "title_episode_file = 'title.episode.tsv.gz'\n",
    "title_principals_file = 'title.principals.tsv.gz'\n",
    "title_rating_file = 'title.ratings.tsv.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_basic = dt.fread(os.path.join(path, name_basics_file), fill=True).to_pandas()\n",
    "title_basic =  dt.fread(os.path.join(path, title_basics_file),fill=True).to_pandas()\n",
    "aka =  dt.fread(os.path.join(path, title_aks_file),fill=True).to_pandas()\n",
    "crew = dt.fread(os.path.join(path, title_crew_file),fill=True).to_pandas()\n",
    "episode = dt.fread(os.path.join(path, title_episode_file),fill=True).to_pandas()\n",
    "principals = dt.fread(os.path.join(path, title_principals_file),fill=True).to_pandas()\n",
    "ratings = dt.fread(os.path.join(path, title_rating_file),fill=True).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2  Process tables for designed schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table: Title Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate original \"genres\" column into three new columns by str.split, and to make sure the dataframe can be read successfully into MySQL database, all the empty column is transferred into np.nan, and the name and order for each column should be same as what we give while creating tables in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the genres column into three new columns\n",
    "titlegenres = TitleBasic['genres'].str.split(',', 3, expand=True)\n",
    "titlegenre = titlegenres.rename(columns={ 0: 'genres1', 1:'genres2', 2:'genres3'})\n",
    "TitleBasic = TitleBasic.drop(['genres'], axis=1)\n",
    "TitleBasic = pd.concat([TitleBasic, titlegenre], axis=1)\n",
    "\n",
    "#TitleBasic dataframe format, replace all the '\\N' into np.nan\n",
    "TitleBasic = TitleBasic.replace({r'\\\\N': np.nan}, regex=True)\n",
    "TitleBasics=TitleBasic.rename(columns={'tconst': 'tb_tconst'})\n",
    "TitleBasics.to_csv(os.path.join(save_path, 'TitleBasics.csv.gz'),  compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tb_tconst</th>\n",
       "      <th>titleType</th>\n",
       "      <th>primaryTitle</th>\n",
       "      <th>originalTitle</th>\n",
       "      <th>isAdult</th>\n",
       "      <th>startYear</th>\n",
       "      <th>endYear</th>\n",
       "      <th>runtimeMinutes</th>\n",
       "      <th>genres1</th>\n",
       "      <th>genres2</th>\n",
       "      <th>genres3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>short</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>False</td>\n",
       "      <td>1894.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Short</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>short</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>Le clown et ses chiens</td>\n",
       "      <td>False</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Short</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>short</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>Pauvre Pierrot</td>\n",
       "      <td>False</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>short</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>Un bon bock</td>\n",
       "      <td>False</td>\n",
       "      <td>1892.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Animation</td>\n",
       "      <td>Short</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>short</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>Blacksmith Scene</td>\n",
       "      <td>False</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Short</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tb_tconst titleType            primaryTitle           originalTitle  \\\n",
       "0  tt0000001     short              Carmencita              Carmencita   \n",
       "1  tt0000002     short  Le clown et ses chiens  Le clown et ses chiens   \n",
       "2  tt0000003     short          Pauvre Pierrot          Pauvre Pierrot   \n",
       "3  tt0000004     short             Un bon bock             Un bon bock   \n",
       "4  tt0000005     short        Blacksmith Scene        Blacksmith Scene   \n",
       "\n",
       "  isAdult  startYear  endYear  runtimeMinutes      genres1 genres2  genres3  \n",
       "0   False     1894.0      NaN             1.0  Documentary   Short           \n",
       "1   False     1892.0      NaN             5.0    Animation   Short           \n",
       "2   False     1892.0      NaN             4.0    Animation  Comedy  Romance  \n",
       "3   False     1892.0      NaN            12.0    Animation   Short           \n",
       "4   False     1893.0      NaN             1.0       Comedy   Short           "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitleBasics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table:  Name Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate original \"primaryProfession\" column into three new columns by str.split, and to make sure the dataframe can be read successfully into MySQL database, all the empty column is transferred into np.nan, and the name and order for each column should be same as what we give while creating tables in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the primaryprofession column into three new columns\n",
    "pripros = NameBasic['primaryProfession'].str.split(',', 3, expand=True)\n",
    "pripro = pripros.rename(columns={ 0: 'primaryProfession1', 1:'primaryProfession2', 2:'primaryProfession3'})\n",
    "NameBasic = NameBasic.drop(['primaryProfession'], axis=1)\n",
    "NameBasic = pd.concat([NameBasic, pripro], axis=1)\n",
    "\n",
    "#drop knownfortitles column\n",
    "NameBasics = NameBasic.drop('knownForTitles', axis=1)\n",
    "#rename the column\n",
    "NameBasics = NameBasics.rename(columns={ 'nconst': 'nb_nconst'})\n",
    "#replace all the /N into np.nan\n",
    "NameBasics = NameBasics.replace({r'\\\\N': np.nan}, regex=True)\n",
    "NameBasics.to_csv(os.path.join(save_path, 'NameBasics.csv.gz'),  compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_nconst</th>\n",
       "      <th>primaryName</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>primaryProfession1</th>\n",
       "      <th>primaryProfession2</th>\n",
       "      <th>primaryProfession3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nm0000001</td>\n",
       "      <td>Fred Astaire</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>actor</td>\n",
       "      <td>miscellaneous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nm0000002</td>\n",
       "      <td>Lauren Bacall</td>\n",
       "      <td>1924.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>actress</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nm0000003</td>\n",
       "      <td>Brigitte Bardot</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>actress</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>music_department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nm0000004</td>\n",
       "      <td>John Belushi</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>soundtrack</td>\n",
       "      <td>writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nm0000005</td>\n",
       "      <td>Ingmar Bergman</td>\n",
       "      <td>1918.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>writer</td>\n",
       "      <td>director</td>\n",
       "      <td>actor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nb_nconst      primaryName  birthYear  deathYear primaryProfession1  \\\n",
       "0  nm0000001     Fred Astaire     1899.0     1987.0         soundtrack   \n",
       "1  nm0000002    Lauren Bacall     1924.0     2014.0            actress   \n",
       "2  nm0000003  Brigitte Bardot     1934.0        NaN            actress   \n",
       "3  nm0000004     John Belushi     1949.0     1982.0              actor   \n",
       "4  nm0000005   Ingmar Bergman     1918.0     2007.0             writer   \n",
       "\n",
       "  primaryProfession2 primaryProfession3  \n",
       "0              actor      miscellaneous  \n",
       "1         soundtrack                     \n",
       "2         soundtrack   music_department  \n",
       "3         soundtrack             writer  \n",
       "4           director              actor  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NameBasics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table:  Title Crew Director"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from the \"TitleCrew\" dataset. In reality, there might be multiple directors participating for one product, therefore, to map this many-to-many or many-to-one relationship, we use the flatten function which has been defined at beginning to process the original \"titlecrew\" table. To make sure the dataframe can be read successfully into MySQL database, all the empty column is transferred into np.nan, and the name and order for each column should be same as what we give while creating tables in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table title crew director\n",
    "TitleCrewDirector = flatten_columns(crew, 'directors', 'tconst', 'director', 'tcd_tconst')\n",
    "TitleCrewDirector.to_csv('TitleCrewDirector.csv.gz', compression='gzip')\n",
    "TitleCrewDirector = dt.fread('TitleCrewDirector.csv.gz',fill=True).to_pandas()\n",
    "\n",
    "#change the order\n",
    "TitleCrewDirector = TitleCrewDirector[['C0','C2','C1']]\n",
    "\n",
    "#rename the columns\n",
    "TitleCrewDirector = TitleCrewDirector.rename(columns={'C0':'idTitleCrewDirector','C2':'tcd_tconst','C1':'director'})\n",
    "\n",
    "#Drop the first row\n",
    "TitleCrewDirector = TitleCrewDirector.drop(TitleCrewDirector.index[0])\n",
    "\n",
    "#replace all the /N into np.nan\n",
    "TitleCrewDirector = TitleCrewDirector.replace({r'\\\\N': np.nan}, regex=True)\n",
    "\n",
    "#make the first id column to be integer\n",
    "TitleCrewDirector['idTitleCrewDirector'] = TitleCrewDirector['idTitleCrewDirector'].round(0).astype(int)\n",
    "TitleCrewDirector.to_csv(os.path.join(save_path, 'TitleCrewDirector.csv.gz'),  compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idTitleCrewDirector</th>\n",
       "      <th>tcd_tconst</th>\n",
       "      <th>director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>nm0005690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0000002</td>\n",
       "      <td>nm0721526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0000003</td>\n",
       "      <td>nm0721526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0000004</td>\n",
       "      <td>nm0721526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0000005</td>\n",
       "      <td>nm0005690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idTitleCrewDirector tcd_tconst   director\n",
       "0                    0  tt0000001  nm0005690\n",
       "1                    1  tt0000002  nm0721526\n",
       "2                    2  tt0000003  nm0721526\n",
       "3                    3  tt0000004  nm0721526\n",
       "4                    4  tt0000005  nm0005690"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitleCrewDirector.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table:  Title Crew Writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from the \"TitleCrew\" dataset too. For similar reason as we given in \"TitleCrewDirector\" dataset, we use the flatten function which has been defined at beginning to process the original \"titlecrew\" table to map the many-to-many or one-to many relationship between product and writer. To make sure the dataframe can be read successfully into MySQL database, all the empty column is transferred into np.nan, and the name and order for each column should be same as what we give while creating tables in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table title crew writer\n",
    "TitleCrewWriter = flatten_columns(crew, 'writers', 'tconst', 'writer', 'tcw_tconst')\n",
    "TitleCrewWriter.to_csv('TitleCrewWriter.csv.gz', compression='gzip')\n",
    "TitleCrewWriter = dt.fread('TitleCrewWriter.csv.gz',fill=True).to_pandas()\n",
    "\n",
    "#change the order\n",
    "TitleCrewWriter = TitleCrewWriter[['C0','C2','C1']]\n",
    "\n",
    "#rename the columns\n",
    "TitleCrewWriter = TitleCrewWriter.rename(columns={'C0':'idTitleCrewcol','C2':'tcw_tconst','C1':'writers'})\n",
    "\n",
    "#Drop the first row\n",
    "TitleCrewWriter = TitleCrewWriter.drop(TitleCrewWriter.index[0])\n",
    "\n",
    "#replace all the /N into np.nan\n",
    "TitleCrewWriter = TitleCrewWriter.replace({r'\\\\N': np.nan}, regex=True)\n",
    "\n",
    "#make the first id column to be integer\n",
    "TitleCrewWriter['idTitleCrewcol'] = TitleCrewWriter['idTitleCrewcol'].round(0).astype(int)\n",
    "TitleCrewWriter.to_csv(os.path.join(save_path, 'TitleCrewWriter.csv.gz'),  compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idTitleCrewcol</th>\n",
       "      <th>tcw_tconst</th>\n",
       "      <th>writers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0000009</td>\n",
       "      <td>nm0085156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0000036</td>\n",
       "      <td>nm0410331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0000076</td>\n",
       "      <td>nm0410331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0000091</td>\n",
       "      <td>nm0617588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0000108</td>\n",
       "      <td>nm0410331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idTitleCrewcol tcw_tconst    writers\n",
       "0               0  tt0000009  nm0085156\n",
       "1               1  tt0000036  nm0410331\n",
       "2               2  tt0000076  nm0410331\n",
       "3               3  tt0000091  nm0617588\n",
       "4               4  tt0000108  nm0410331"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitleCrewWriter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table:  Title AKA Attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from the \"TitleAKA\" dataset. In reality, there might be multiple names or titles while movies are issued in various countris or areas, therefore, to map this many-to-many or many-to-one relationship, we use the flatten function which has been defined at beginning to process the original TitleAKA table. To make sure the dataframe can be read successfully into MySQL database, all the empty column is transferred into np.nan, and the name and order for each column should be same as what we give while creating tables in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table for titleAKA_attribute\n",
    "df = aka.reset_index()\n",
    "df_t = df.loc[df['types'] != \"\\\\N\"].dropna(subset=['types'])\n",
    "flattened_df = pd.DataFrame(df_t['types'].str.split('\\x02').values.tolist(), index = df_t['index']).stack()\n",
    "title_aks_attributes_df = flattened_df.reset_index()[[0, 'index']] \n",
    "title_aks_attributes_df.columns = ['type', 'tat_idAKA'] # renaming\n",
    "title_aks_attributes_df.to_csv('TitleAkaAttribute.csv.gz',  compression='gzip')\n",
    "\n",
    "#change the order\n",
    "TitleAkaAttribute = TitleAkaAttribute[['C0', 'taa_idAKA','attribute']]\n",
    "\n",
    "#rename the columns\n",
    "TitleAkaAttribute = TitleAkaAttribute.rename(columns={'C0':'idTitleAkaAttributes','attribute':'taa_attribute'})\n",
    "\n",
    "#replace all the /N into np.nan\n",
    "TitleAkaAttribute = TitleAkaAttribute.replace({r'\\\\N': np.nan}, regex=True)\n",
    "TitleAkaAttribute.to_csv(os.path.join(save_path, 'TitleAkaAttribute.csv.gz'),  compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idTitleAkaAttributes</th>\n",
       "      <th>taa_idAKA</th>\n",
       "      <th>taa_attribute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>literal title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>literal title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>literal English title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>literal title</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>literal title</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idTitleAkaAttributes  taa_idAKA          taa_attribute\n",
       "0                     0          1          literal title\n",
       "1                     1         11          literal title\n",
       "2                     2         14  literal English title\n",
       "3                     3         24          literal title\n",
       "4                     4         26          literal title"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitleAkaAttribute.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table:  Title AKA Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This \"type\" dataset comes from the \"TitleAKA\" dataset. In reality, there might be various types while the movie are issued, therefore, to map this many-to-many or many-to-one relationship, we use the flatten function which has been defined at beginning to process the original TitleAKA table. To make sure the dataframe can be read successfully into MySQL database, all the empty column is transferred into np.nan, and the name and order for each column should be same as what we give while creating tables in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aka.reset_index()\n",
    "TitleAkaType = flatten_columns(df, 'types', 'index', 'type', 'tat_idAKA')\n",
    "TitleAkaType.to_csv('TitleAkaType.csv.gz',  compression='gzip')\n",
    "TitleAkaType = dt.fread('TitleAkaType.csv.gz',fill=True).to_pandas()\n",
    "\n",
    "#change the order\n",
    "TitleAkaType = TitleAkaType[['C0', 'tat_idAKA','type']]\n",
    "\n",
    "#rename the columns\n",
    "TitleAkaType = TitleAkaType.rename(columns={'C0':'idTitleAkaType'})\n",
    "\n",
    "#replace all the /N into np.nan\n",
    "TitleAkaType = TitleAkaType.replace({r'\\\\N': np.nan}, regex=True)\n",
    "TitleAkaType.to_csv(os.path.join(save_path, 'TitleAkaType.csv.gz'),  compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idTitleAkaType</th>\n",
       "      <th>tat_idAKA</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>imdbDisplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>imdbDisplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>imdbDisplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>imdbDisplay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idTitleAkaType  tat_idAKA         type\n",
       "0               0          0  imdbDisplay\n",
       "1               1          2  imdbDisplay\n",
       "2               2          3  imdbDisplay\n",
       "3               3          4  imdbDisplay\n",
       "4               4          6     original"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitleAkaType.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table:  Title Principals Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is comes from \"TitlePrincipals\" dataset, a person may play multple roles in the same movie, therefore, the values for \"character\" column having multiple values in some rows. We separate one cell by string function and generate different rows while each row represents for one character. This makes sure the database fits for BCNF. Also the empty cells are transferred into np.nan and rename/reorder operations are given to make sure the dataframe can be load into database successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table for titlePrincicleCharacters\n",
    "principals['characters'] = principals['characters'].str.lstrip('[').str.rstrip(']').str.replace('\"','')\n",
    "df = title_principals_df[['characters']].reset_index()\n",
    "PrincipalsCharacters = flatten_columns(df, 'characters', 'index', 'character', 'pc_idTitlePrincipals')\n",
    "PrincipalsCharacters.to_csv('TitlePrincipalsCharacters.csv.gz',  compression='gzip')\n",
    "PrincipalsCharacters = dt.fread('PrincipalsCharacters.csv.gz',fill=True).to_pandas()\n",
    "\n",
    "#change the order\n",
    "PrincipalsCharacters = PrincipalsCharacters[['C0', 'pc_idTitlePrincipals','character']]\n",
    "\n",
    "#rename the columns\n",
    "PrincipalsCharacters = PrincipalsCharacters.rename(columns={'C0':'idPrincipalsCharacters'})\n",
    "\n",
    "#replace all the /N into np.nan\n",
    "PrincipalsCharacters = PrincipalsCharacters.replace({r'\\\\N': np.nan}, regex=True)\n",
    "PrincipalsCharacters.to_csv(os.path.join(save_path, 'PrincipalsCharacters.csv.gz'),  compression='gzip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idPrincipalsCharacters</th>\n",
       "      <th>pc_idTitlePrincipals</th>\n",
       "      <th>character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Self</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Blacksmith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>Assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>Sneezing Man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>Miss Geraldine Holbrook (Miss Jerry)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idPrincipalsCharacters  pc_idTitlePrincipals  \\\n",
       "0                       0                     0   \n",
       "1                       1                    11   \n",
       "2                       2                    12   \n",
       "3                       3                    21   \n",
       "4                       4                    24   \n",
       "\n",
       "                              character  \n",
       "0                                  Self  \n",
       "1                            Blacksmith  \n",
       "2                             Assistant  \n",
       "3                          Sneezing Man  \n",
       "4  Miss Geraldine Holbrook (Miss Jerry)  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PrincipalsCharacters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table:  Title Principals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We delete the \"characters\" column from this dataset as the \"characters\" infromation is given in the \"PrincipalCharacters\" dataset. And empty cells are transferred into np.nan and rename/reorder operations are given to make sure the dataframe can be load into database successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the id to Principals\n",
    "Principal.reset_index(level=0, inplace=True)\n",
    "#drop character column\n",
    "TitlePrincipals = Principal.drop('characters', axis=1)\n",
    "#rename columns \n",
    "TitlePrincipals = TitlePrincipals.rename(columns={ 'index': 'idTitlePrincipals', 'tconst':'tp_tconst', 'ordering':'tp_ordering','nconst':'tp_nconst'})\n",
    "#replace all the /N into np.nan\n",
    "TitlePrincipals = TitlePrincipals.replace({r'\\\\N': np.nan}, regex=True)\n",
    "#remove the rows do not contains in the primary table NameBasics\n",
    "TitlePrincipals = TitlePrincipals.loc[TitlePrincipals.tp_nconst.isin(NameBasics.nb_nconst)]\n",
    "\n",
    "#remove the rows do not contains in the primary table TitleBasics\n",
    "TitlePrincipals = TitlePrincipals.loc[TitlePrincipals.tp_tconst.isin(TitleBasic.tb_tconst)]\n",
    "TitlePrincipals.to_csv(os.path.join(save_path, 'TitlePrincipals.csv.gz'),  compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idTitlePrincipals</th>\n",
       "      <th>tp_tconst</th>\n",
       "      <th>tp_ordering</th>\n",
       "      <th>tp_nconst</th>\n",
       "      <th>category</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>nm1588970</td>\n",
       "      <td>self</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>2</td>\n",
       "      <td>nm0005690</td>\n",
       "      <td>director</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>3</td>\n",
       "      <td>nm0374658</td>\n",
       "      <td>cinematographer</td>\n",
       "      <td>director of photography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0000002</td>\n",
       "      <td>1</td>\n",
       "      <td>nm0721526</td>\n",
       "      <td>director</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0000002</td>\n",
       "      <td>2</td>\n",
       "      <td>nm1335271</td>\n",
       "      <td>composer</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idTitlePrincipals  tp_tconst  tp_ordering  tp_nconst         category  \\\n",
       "0                  0  tt0000001            1  nm1588970             self   \n",
       "1                  1  tt0000001            2  nm0005690         director   \n",
       "2                  2  tt0000001            3  nm0374658  cinematographer   \n",
       "3                  3  tt0000002            1  nm0721526         director   \n",
       "4                  4  tt0000002            2  nm1335271         composer   \n",
       "\n",
       "                       job  \n",
       "0                           \n",
       "1                           \n",
       "2  director of photography  \n",
       "3                           \n",
       "4                           "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitlePrincipals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table: TitleEpisode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the dataframe can be read successfully into MySQL database, all the empty column is transferred into np.nan, and the name and order for each column should be same as what we give while creating tables in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the index as keys\n",
    "Episode.reset_index(level=0, inplace=True)\n",
    "#replace all the /N into np.nan\n",
    "Episode = Episode.replace({r'\\\\N': np.nan}, regex=True)\n",
    "#rename the columns\n",
    "TitleEpisode = Episode.rename(columns={ 'index': 'idTitleEpisode', 'tconst':'te_tconst'})\n",
    "#froeign key check\n",
    "#remove the rows do not contains in the primary table TitleBasics\n",
    "TitleEpisode = TitleEpisode.loc[TitleEpisode.parentTconst.isin(TitleBasics.tb_tconst)]\n",
    "\n",
    "TitleEpisode = TitleEpisode.loc[TitleEpisode.te_tconst.isin(TitleBasics.tb_tconst)]\n",
    "TitleEpisode.to_csv(os.path.join(save_path, 'TitleEpisode.csv.gz'),  compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idTitleEpisode</th>\n",
       "      <th>te_tconst</th>\n",
       "      <th>parentTconst</th>\n",
       "      <th>seasonNumber</th>\n",
       "      <th>episodeNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0041951</td>\n",
       "      <td>tt0041038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0042816</td>\n",
       "      <td>tt0989125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0042889</td>\n",
       "      <td>tt0989125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0043426</td>\n",
       "      <td>tt0040051</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0043631</td>\n",
       "      <td>tt0989125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idTitleEpisode  te_tconst parentTconst  seasonNumber  episodeNumber\n",
       "0               0  tt0041951    tt0041038           1.0            9.0\n",
       "1               1  tt0042816    tt0989125           1.0           17.0\n",
       "2               2  tt0042889    tt0989125           NaN            NaN\n",
       "3               3  tt0043426    tt0040051           3.0           42.0\n",
       "4               4  tt0043631    tt0989125           2.0           16.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitleEpisode.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table: TitleAKA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We delete \"types\" and \"attributes\" columns from original \"titleAKA\" dataset as both columns' information have been given in \"TitleAKATypes\" and \"TitleAKAattributes\" datasets. After deletion, empty cells are transferred into np.nan and rename/reorder operations are given to make sure the dataframe can be load into database successfully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the columns\n",
    "TitleAka = Aka.drop('types', axis=1)\n",
    "TitleAka = TitleAka.drop('attributes', axis=1)\n",
    "#add the index\n",
    "TitleAka.reset_index(level=0, inplace=True)\n",
    "#replace all the /N into np.nan\n",
    "TitleAka = TitleAka.replace({r'\\\\N': np.nan}, regex=True)\n",
    "#rename the columns\n",
    "TitleAka = TitleAka.rename(columns={ 'index': 'idTitleAKA', 'titleId':'titleID'})\n",
    "#froeign key check\n",
    "#remove the rows do not contains in the primary table TitleBasics\n",
    "TitleAKA = TitleAka.loc[TitleAka.titleID.isin(TitleBasics.tb_tconst)]\n",
    "TitleAKA.to_csv(os.path.join(save_path, 'TitleAKA.csv.gz'), compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idTitleAKA</th>\n",
       "      <th>titleID</th>\n",
       "      <th>ordering</th>\n",
       "      <th>title</th>\n",
       "      <th>region</th>\n",
       "      <th>language</th>\n",
       "      <th>isOriginalTitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>1</td>\n",
       "      <td>Карменсіта</td>\n",
       "      <td>UA</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>2</td>\n",
       "      <td>Carmencita</td>\n",
       "      <td>DE</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>3</td>\n",
       "      <td>Carmencita - spanyol tánc</td>\n",
       "      <td>HU</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>4</td>\n",
       "      <td>Καρμενσίτα</td>\n",
       "      <td>GR</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tt0000001</td>\n",
       "      <td>5</td>\n",
       "      <td>Карменсита</td>\n",
       "      <td>RU</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idTitleAKA    titleID  ordering                      title region language  \\\n",
       "0           0  tt0000001         1                 Карменсіта     UA            \n",
       "1           1  tt0000001         2                 Carmencita     DE            \n",
       "2           2  tt0000001         3  Carmencita - spanyol tánc     HU            \n",
       "3           3  tt0000001         4                 Καρμενσίτα     GR            \n",
       "4           4  tt0000001         5                 Карменсита     RU            \n",
       "\n",
       "  isOriginalTitle  \n",
       "0           False  \n",
       "1           False  \n",
       "2           False  \n",
       "3           False  \n",
       "4           False  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitleAKA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table: TitleRatings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure the dataframe can be read successfully into MySQL database, all the empty column is transferred into np.nan, and the name and order for each column should be same as what we give while creating tables in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all the /N into np.nan\n",
    "TitleRating = Rating.replace({r'\\\\N': np.nan}, regex=True)\n",
    "#rename the columns\n",
    "TitleRating = TitleRating.rename(columns={'tconst':'tr_tconst'})\n",
    "#froeign key check\n",
    "#remove the rows do not contains in the primary table TitleBasics\n",
    "TitleRating = TitleRating.loc[TitleRating.tr_tconst.isin(TitleBasics.tb_tconst)]\n",
    "TitleRating.to_csv(os.path.join(save_path, 'TitleRating.csv.gz'),  compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tr_tconst</th>\n",
       "      <th>averageRating</th>\n",
       "      <th>numVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0000001</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0000002</td>\n",
       "      <td>6.1</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt0000003</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0000004</td>\n",
       "      <td>6.2</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0000005</td>\n",
       "      <td>6.2</td>\n",
       "      <td>2150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tr_tconst  averageRating  numVotes\n",
       "0  tt0000001            5.6      1655\n",
       "1  tt0000002            6.1       199\n",
       "2  tt0000003            6.5      1366\n",
       "3  tt0000004            6.2       121\n",
       "4  tt0000005            6.2      2150"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TitleRating.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table: KnownForTitles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset comes from original \"NameBasic\" datasets, the person might have multiple masterpieces, to map this one-to-many relationship, we use flatten function to transfer it into \"KnownForTitles\" dataset, each row represents the relationship between one person and one of his/her masterpiece. To make sure the dataframe can be read successfully into MySQL database, all the empty column is transferred into np.nan, and the name and order for each column should be same as what we give while creating tables in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_for_titles_df = flatten_columns(name_basic, 'knownForTitles', 'nconst', 'kt_tconst', 'kt_nconst')\n",
    "#change the order\n",
    "KnownForTitles = known_for_titles_df[['nconst','kt_nconst','kt_tconst']]\n",
    "#rename the columns\n",
    "KnownForTitles = KnownForTitles.rename(columns={'nconst':'idNameTitle','kt_nconst':'kt_nconst','kt_tconst':'kt_tconst'})\n",
    "#replace all the /N into np.nan\n",
    "KnownForTitles = KnownForTitles.replace({r'\\\\N': np.nan}, regex=True)\n",
    "#make the first id column to be integer\n",
    "KnownForTitles['idNameTitle'] = KnownForTitles['idNameTitle'].round(0).astype(int)\n",
    "KnownForTitles.to_csv('KnownForTitles.csv.gz',  compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idNameTitle</th>\n",
       "      <th>kt_nconst</th>\n",
       "      <th>kt_tconst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nm0000001</td>\n",
       "      <td>tt0050419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nm0000001</td>\n",
       "      <td>tt0031983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>nm0000001</td>\n",
       "      <td>tt0072308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>nm0000001</td>\n",
       "      <td>tt0053137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>nm0000002</td>\n",
       "      <td>tt0037382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idNameTitle  kt_nconst  kt_tconst\n",
       "0            0  nm0000001  tt0050419\n",
       "1            1  nm0000001  tt0031983\n",
       "2            2  nm0000001  tt0072308\n",
       "3            3  nm0000001  tt0053137\n",
       "4            4  nm0000002  tt0037382"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KnownForTitles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3  Load processed tables to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for table_name in TABLES:\n",
    "    table_description = TABLES[table_name]\n",
    "    try:\n",
    "        print(\"Creating table {}: \".format(table_name), end='')\n",
    "        db_cursor.execute(table_description)\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "            print(\"already exists.\")\n",
    "        else:\n",
    "            print(err.msg)\n",
    "    else:\n",
    "        print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cursor.execute(\"SHOW TABLES\")\n",
    "for table in db_cursor:\n",
    "\tprint(table)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diaable the foreign key check to avoid errors during loading data\n",
    "db_cursor.execute(\"SET GLOBAL FOREIGN_KEY_CHECKS=0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write the TitleBasic dataframe into related table\n",
    "TitleBasic.to_sql('TitleBasics', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the NameBasics dataframe into related table\n",
    "NameBasics.to_sql('NameBasics', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the TitlePrincipals dataframe into related table\n",
    "TitlePrincipals.to_sql('TitlePrincipals', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the TitleEposide dataframe into related table\n",
    "TitleEpisode.to_sql('TitleEpisode', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the TitleAKA dataframe into related table\n",
    "TitleAKA.to_sql('TitleAKA', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the TitleRating dataframe into related table\n",
    "TitleRating.to_sql('TitleRating', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the TitleAkaAttribute dataframe into related table\n",
    "TitleAkaAttribute.to_sql('TitleAkaAttribute', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the TitleCrewDirector dataframe into related table\n",
    "TitleCrewDirector.to_sql('TitleCrewDirector', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the TitleCrewWriter dataframe into related table\n",
    "TitleCrewWriter.to_sql('TitleCrewWriter', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the KnownForTitles dataframe into related table\n",
    "KnownForTitles.to_sql('KnownForTitles', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the TitleAkaType dataframe into related table\n",
    "TitleAkaType.to_sql('TitleAkaType', con = engine, if_exists = 'append',index=False, chunksize=10000)\n",
    "#write the PrincipalsCharacters dataframe into related table\n",
    "PrincipalsCharacters.to_sql('PrincipalsCharacters', con = engine, if_exists = 'append',index=False, chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 Update calculated columns\n",
    "After loading the data, execute UPDATE statements for the two newly created columns in (2C). You may interpret what appearing in movies means and what you classify as movies -- just make it clear in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##UPDATE AGE\n",
    "#change the type of birthyear to int\n",
    "db_cursor.execute('ALTER TABLE NameBasics MODIFY COLUMN birthYear INT null;')\n",
    "\n",
    "#update the age by the calculated value with current year\n",
    "db_cursor.execute('SET SQL_SAFE_UPDATES = 0; UPDATE NameBasics SET age = YEAR(CURDATE()) - birthYear;')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the appearing in movies as following: if one person is the principals of the movie, he/she will be considered as apearing in the moview.\n",
    "<br>\n",
    "We define the movie as following: if one title do not has episode, we condsider it as a movie. In that case, the movie will be have a title which will not show in Title Episode table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##UPDATE MOVIES\n",
    "#To save the time, we create a temproty table for saving the joint table including rows included in TitlePrincipals and not included in TitleEpisode\n",
    "db_cursor.execute(\"\"\"CREATE TEMPORARY TABLE IF NOT EXISTS onlyMovie AS (\n",
    "                     SELECT * FROM TitlePrincipals\n",
    "                     LEFT JOIN TitleEpisode ON TitleEpisode.te_tconst = TitlePrincipals.tp_tconst\n",
    "                     WHERE TitleEpisode.te_tconst IS NULL)\"\"\")\n",
    "\n",
    "#calculate number of movies by counting the rows in the temperoty table\n",
    "db_cursor.execute(\"\"\"UPDATE NameBasics SET numberOfMovies = (SELECT COUNT(*) FROM onlyMovie WHERE onlyMovie.tp_nconst = NameBasics.nb_nconst);\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Result of adding two calculated columns](pics\\task5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6 Add Triggers\n",
    "Add triggers to the appropriate tables so that the newly created columns in (2C) are automatically updated when new data in inserted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Triggers for Age: Similar to the calcualted colum, it will calculate a value before a new item inserted into a the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONLY run the trigger if the age is not given\n",
    "age_trigger_sql=\"\"\"DELIMITER $$\n",
    "CREATE\n",
    "    TRIGGER age_calculation AFTER INSERT \n",
    "    ON NameBasics\n",
    "    FOR EACH ROW BEGIN\n",
    "\n",
    "        update NameBasics\n",
    "        set NameBasics.age = YEAR(CURDATE()) - NEW.birthYear\n",
    "        where NameBasics.nb_nconst = NEW.nb_nconst;\n",
    "\n",
    "    END$$\n",
    "DELIMITER ;\"\"\"\n",
    "\n",
    "db_cursor.execute(age_trigger_sql)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Result of adding two triggers shown in MySQL workbench](pics\\age_trigger.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Triggers for number of movies: Similar to the calcualted colum, it will calculate a value before a new item inserted into a the table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIMILAR BUT ADD DELIMITER\n",
    "movie_trigger_sql =\"\"\"delimiter $$\n",
    "                      CREATE TRIGGER numberOfMovies_calculation\n",
    "                      before INSERT\n",
    "                      ON NameBasics\n",
    "                      FOR EACH ROW\n",
    "                        UPDATE NameBasics\n",
    "                        SET NameBasics.numberOfMovies = ( with tp_groupby as ( SELECT tp_nconst, COUNT(distinct tp_tconst) as n_movies \n",
    "                        FROM TitlePrincipals \n",
    "                        where tp_tconst not in (select te_tconst from TitleEpisode) \n",
    "                        group by tp_nconst)\n",
    "                        select tp_groupby.n_movies from tp_groupby\n",
    "                        where tp_groupby.tp_nconst = NameBasics.nb_nconst); \n",
    "                      END$$\"\"\"\n",
    "\n",
    "db_cursor.execute(movie_trigger_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Result of adding two triggers shown in MySQL workbench](pics\\movie_trigger.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7 Create a view\n",
    " Create a view that lists the name of each actor, their age, whether they are dead or not, and how many movies they are known for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_sql=\"\"\"CREATE OR REPLACE VIEW actors AS\n",
    "              With NumKnowFor AS (Select kt_nconst, count(*) as n_kf from KnownForTitles group by kt_nconst) \n",
    "              SELECT distinct nb.nb_nconst, nb.primaryName, nb.age, (nb.deathYear is not null) as deadorNot, NumKnowFor.n_kf as numKnownForTitle \n",
    "              FROM NameBasics nb\n",
    "              Join NumKnowFor on NumKnowFor.kt_nconst=nb.nb_nconst\n",
    "              Join (Select distinct tp_nconst FROM TitlePrincipals Where TitlePrincipals.category = 'actor') AS tt \n",
    "              ON tt.tp_nconst = nb.nb_nconst;\"\"\"\n",
    "\n",
    "db_cursor.execute(create_sql)\n",
    "\n",
    "db_cursor.execute(\"\"\"select * from actors limit 10\"\"\")\n",
    "db_cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![First 10 samples of created actors view](pics\\task7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8 Finds the number of seasons for each TV series and Plot Histogram\n",
    "Write a query that finds the number of seasons for each TV series. Using the results of the query create a histogram (frequency plot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_season_sql = \"\"\" SELECT titlebasics.primaryTitle, parentTconst, max(seasonNumber) as n_seasons \n",
    "from TitleEpisode \n",
    "join TitleBasics on TitleBasics.tb_tconst = TitleEpisode.te_tconst \n",
    "WHERE seasonNumber IS NOT NULL GROUP BY parentTconst; \"\"\"\n",
    "\n",
    "n_seasons_df = pd.read_sql(n_season_sql, con = engine)\n",
    "n_seasons_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![First 5 samples of queried result ](pics\\task8_df.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = n_seasons_df.copy()\n",
    "ax =df.plot.hist(by = 'n_seasons', bins=100)\n",
    "ax.title('Histogram for all TV series')\n",
    "df = df.loc[df.n_seasons < 100]\n",
    "ax =df.plot.hist(by = 'n_seasons', bins=100)\n",
    "ax.title('Histogram for TV series which season number is less than 100')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Histogram for all TV series](pics\\task8_whole.png)\n",
    "![Histogram for TV series which has season number is less than 100 for detailed look](pics\\task8_whole.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9 Build a function to add actors\n",
    "Build a function in your code or a stored procedure in the database (approach is your choice) called addActor() that adds a new actor to the database: this requires updating several tables, so the insertions must occur within a transaction in order to function properly in a concurrent environment. Test your function by inserting a new actor -- you may make up a name and associated information. Show evidence  in your notebook that the actor was properly inserted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an actor will make changes to those three tables: NameBasics table by adding a person information, TitlePrincipals by adding a category associated with a title(movie or tv, etc), KnownForTitle table by having the titles that this actor are known for. \n",
    "<br>\n",
    "In summary, an actor should have following attributes: nconst, tconst, ordering and principals. We assume that the actor added is already existed in the NameBasics and the tconst is already exist into TitleBasics too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we stated, we assume an actor exists in name basic table. If not, there is an extra step to add person in Name Basic, which is out of our consideration. Then for a person in Name Basics, we add an actor by asscosiating it with a production title(movie, TV, etc) and some characters in the production. For example, we have a person(nm0000001) which plays roles as Elizabeth, Queen, Layard in a title(tt0000050). So we can see that before adding this actor, the numer of movies of this person is 139.\n",
    "<br>\n",
    "![Table Name basic before adding actors ](pics\\figure_Taks9\\NameBasics_before.png)\n",
    "<br>\n",
    "<br>\n",
    "After adding this actor, the numer of movies of this person becomes 140. Principal characters table is also updated. Three defined characters are shown as below. More over, we can directly query actor information related to this title in Title Principals table \n",
    "<br>\n",
    "<br>\n",
    "![Table Name basic after adding actors ](pics\\figure_Taks9\\NameBasics_After.png)\n",
    "<br>\n",
    "![Table Title Characters after adding actors ](pics\\figure_Taks9\\PrincipalCharacters.png)\n",
    "<br>\n",
    "![Table Title Principal after adding actors ](pics\\figure_Taks9\\TitlePrincipals2.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection.autocommit = True\n",
    "\n",
    "def addActor(nconst, tconst, ordering, principals):\n",
    "    #get the max index for current table and the newidex=max(index+1)\n",
    "    db_cursor.execute('SELECT MAX(idTitlePrincipals) FROM TitlePrincipals')\n",
    "    max_idTitlePrincipals = db_cursor.fetchone()\n",
    "    new_idTitlePrincipals = max_idTitlePrincipals[0]+1\n",
    "    db_cursor.execute('INSERT IGNORE INTO TitlePrincipals(idTitlePrincipals, tp_tconst, tp_ordering, tp_nconst, category) VALUES (%s,%s,%s,%s,%s)',(new_idTitlePrincipals, tconst, ordering, nconst, 'actor'))\n",
    "    #SEPERATE THE PRINCIPALS IF IT HAS MULTIPLE PRINCIPALS\n",
    "    roles = str.split(principals,',')\n",
    "    db_cursor.execute('SELECT MAX(idPrincipalsCharacters) FROM PrincipalsCharacters')\n",
    "    max_idPrincipalsCharacters = db_cursor.fetchone()\n",
    "    max_idPrincipalsCharacters = max_idPrincipalsCharacters[0]\n",
    "    #insert each principal of this new record as a new row\n",
    "    i=0\n",
    "    while i < len(roles):\n",
    "        max_idPrincipalsCharacters = max_idPrincipalsCharacters+i+1\n",
    "        db_cursor.execute('INSERT IGNORE INTO PrincipalsCharacters(idPrincipalsCharacters, pc_idTitlePrincipals, `character`) VALUES (%s,%s,%s)',(max_idPrincipalsCharacters,new_idTitlePrincipals,roles[i])) \n",
    "        i+=1\n",
    "    #check whether the tconst is a movie or not, if is the movie, then update the numOfMovies = numOfMovies + 1\n",
    "    db_cursor.execute(\"SELECT count(*) FROM TitleEpisode WHERE te_tconst = %s or parentTconst = %s\",(tconst,tconst))\n",
    "    numEp = db_cursor.fetchone()\n",
    "    numEp = numEp[0]\n",
    "    if numEp < 1: \n",
    "        db_cursor.execute('UPDATE NameBasics SET numberOfMovies = numberOfMovies+1 WHERE nb_nconst =%s', (nconst,))      \n",
    "     return (\"Insert Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test example:\n",
    "addActor('nm0000001', 'tt0000050', 1, 'Elizabeth, Queen, Layard')\n",
    "\n",
    "#check the result:\n",
    "db_cursor.execute(\"SELECT * FROM TitlePrincipals WHERE tp_nconst = 'nm0000001' AND tp_tconst = 'tt0000050'\")\n",
    "db_cursor.fetchall()\n",
    "\n",
    "db_cursor.execute(\"SELECT * FROM PrincipalsCharacters WHERE pc_idTitlePrincipals = 41693055'\")\n",
    "db_cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10 Build a function to delete actors\n",
    "Build a function in your code or a stored procedure in the database (approach is your choice) called deleteActor() that removes an actor from the database: this requires updating several tables, so the deletions must occur within a transaction in order to function properly in a concurrent environment. Test your function by deleting a new actor inserted in (9) -- show evidence that the removal was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, deleting an actor will affect those three tables. It is basically remove the relationship between person and title. Here we will delete the actor (nm0617588) from a title (tt0000417). Before we delete it, in Table Name basic, the number of movies the person appears is 545. We can also find this actor in Principal characters table and title principals table.\n",
    "<br>\n",
    "![Table Name basic before deleting actors ](pics\\figure_task10\\NameBasics_before.png)\n",
    "<br>\n",
    "\n",
    "![Table Title Characters after deleting actors ](pics\\figure_task10\\PrincipalCharacters_before.png)\n",
    "<br>\n",
    "![Table Title Principal after deleting actors ](pics\\figure_task10\\TitlePrincipals_before.png)\n",
    "<br>\n",
    "<br>\n",
    "After deleting this actor, the numer of movies of this person becomes 544, indicating the record is deleted. Principal characters table and title principals table are also updated. We cannot get query result out of table.\n",
    "<br>\n",
    "<br>\n",
    "![Table Name basic after adding actors ](pics\\figure_task10\\NameBasics_After.png)\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_connection.autocommit = True\n",
    "def deleteActor(nconst, tconst, ordering):\n",
    "    #find the idTitlePrincipals for row to be deleted\n",
    "    db_cursor.execute(\"SELECT idTitlePrincipals FROM TitlePrincipals WHERE tp_tconst = %s AND tp_ordering=%s AND tp_nconst = %s AND category = 'actor'\",(tconst, ordering, nconst))\n",
    "    find_idTitlePrincipals = db_cursor.fetchone()\n",
    "    find_idTitlePrincipals = find_idTitlePrincipals[0]\n",
    "    #delete the row from the TitlePrincipals\n",
    "    db_cursor.execute(\"DELETE FROM TitlePrincipals WHERE idTitlePrincipals = %s\",(find_idTitlePrincipals,))\n",
    "    #delete the row from the PrincipalsCharacters\n",
    "    db_cursor.execute(\"DELETE FROM PrincipalsCharacters WHERE pc_idTitlePrincipals = %s\",(find_idTitlePrincipals,))\n",
    "    #check whether the tconst is a movie or not, if is the movie, then update the numOfMovies = numOfMovies - 1\n",
    "    db_cursor.execute(\"SELECT count(*) FROM TitleEpisode WHERE te_tconst = %s or parentTconst = %s\",(tconst,tconst))\n",
    "    numEp = db_cursor.fetchone()\n",
    "    numEp = numEp[0]\n",
    "    if numEp < 1: \n",
    "        db_cursor.execute('UPDATE NameBasics SET numberOfMovies = numberOfMovies-1 WHERE nb_nconst =%s', (nconst,))\n",
    "    return (\"Delete Successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test example:\n",
    "deleteActor('nm0617588', 'tt0000417',1)\n",
    "\n",
    "#check the result:\n",
    "db_cursor.execute(\"SELECT * FROM TitlePrincipals WHERE tp_nconst = 'nm0617588' AND tp_tconst = 'tt0000417'\")\n",
    "db_cursor.fetchall()\n",
    "\n",
    "db_cursor.execute(\"SELECT * FROM NameBasics WHERE nb_nconst = 'nm0617588'\")\n",
    "db_cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 11 Query actors\n",
    "Write a query to retrieve the names and ages of all actors who appeared in more than two movies (but not TV series) which an above average rating. Show the results of the query in your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, we first calculatet the average rating of all movies and then use calculated number to further select the actors which appeared in more than two movies has an above average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the total average rating \n",
    "db_cursor.execute(\"\"\"SELECT avg(averageRating)'totalavg' FROM TitleRating \n",
    "                    where tp_tconst not in (select te_tconst from TitleEpisode) \"\"\")\n",
    "totalavg = db_cursor.fetchone()\n",
    "totalavg = max_idTitlePrincipals[0]\n",
    "#output the actors with more than 2 movies having above average ratings (rating > average rating)\n",
    "db_cursor.execute(\"\"\"SELECT primaryName, age FROM NameBasics \n",
    "                     LEFT JOIN TitlePrincipals ON TitlePrincipals.tp_nconst = NameBasics.nb_nconst\n",
    "                     LEFT JOIN TiTleRating ON TitleRating.tr_tconst = TitlePrincipals.tp_tconst\n",
    "                     WHERE TitleRating.averageRating > %s AND TiTleRating.tr_tconst not in (select te_tconst from TitleEpisode AND category = category = 'actor')\n",
    "                     GROUP BY primaryName\n",
    "                     HAVING count(primaryName)>2\"\"\",(totalavg,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 12 Index\n",
    "Write a query that finds an actor by name (pick a name). Measure the execution time of the query. Then create an index that would improve the performance of the query and then run and measure it again. Show the difference and comment on why that's the case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the excutation time and the rows shown in the plots, we can tell the query is not efficiency. From figure explain analyze result, we can see the process takes more than 1048260 seconds to query this information. From figure explain result we can see it used huge number of rows when querying one result.\n",
    "<br>\n",
    "\n",
    "![Explain the query result before adding index](pics\\figure_task12\\12_original_no_analyze.png)\n",
    "\n",
    "\n",
    "![Explain analyze the query result before adding index](pics\\figure_task12\\12_oringinal_analyze.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cursor.execute(\" EXPLAIN select primaryName from actors where primaryName='Fred Astraire'; \")\n",
    "analyze_fetched = db_cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_fetched = db_cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cursor.execute(\" EXPLAIN ANALYZE select primaryName from actors where primaryName='Fred Astraire'; \")\n",
    "analyze_fetched = db_cursor.fetchall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the performance should be improved by adding a index. However based on our research, MySQL did not support the index feature for view table as stated in http://dev.mysql.com/doc/refman/5.7/en/view-restrictions.html\n",
    "<br>\n",
    "View processing is not optimized:\n",
    "\n",
    "1. It is not possible to create an index on a view.\n",
    "\n",
    "2. Indexes can be used for views processed using the merge algorithm. However, a view that is processed with the temptable algorithm is unable to take advantage of indexes on its underlying tables (although indexes can be used during generation of the temporary tables).\n",
    "<br>\n",
    "We also tried to add an index to a view but get an error \"Error Code: 1347. 'practicum2.actors' is not BASE TABLE\"\n",
    "<br>\n",
    "So we found a workaround inspired by https://stackoverflow.com/questions/38391726/mysql-index-on-view-not-working to create a well-indexed table and then improve our performance based on new tables. \n",
    "\n",
    "The steps we achieve it are:\n",
    "1. Create a table according to my needs, having the exact same structure as the view, \n",
    "2. running a sql to insert rows of view into new table\n",
    "3. Add a index for primaryName \n",
    "\n",
    "By having a well-indexed table, we can largely increase the performance. Note that this table will not updated with raw data table. \n",
    "<br>\n",
    "From the explain and explain analyze result, we can see only one row is used in query and it takes only 1.1 seconds which is impressive.\n",
    "\n",
    "![Explain the query result after adding index](pics\\figure_task12\\12_no_analyze.png)\n",
    "<br>\n",
    "![Explain analyze the query result after adding index](pics\\figure_task12\\12_explain.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_index_sql =\"\"\" create table actorsView (nb_nconst varchar(500),\n",
    "primaryName varchar(500),\n",
    "age int,\n",
    "deadorNot int,\n",
    "numKnownForTitle bigint\n",
    ");\n",
    "TRUNCATE actorsView; \n",
    "INSERT INTO actorsView SELECT * FROM actors;\n",
    "ALTER TABLE actorsView ADD INDEX idx_primaryName(primaryName);\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cursor.execute(\" EXPLAIN select primaryName from actors where primaryName='Fred Astraire'; \")\n",
    "analyze_fetched = db_cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_cursor.execute(\" EXPLAIN ANALYZE select primaryName from actors where primaryName='Fred Astraire'; \")\n",
    "analyze_fetched = db_cursor.fetchall()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
